{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Samar Desktop\\Samar\\Year_4\\Graduation Project\\Harvard Dataset\\MobileNetV2.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Samar%20Desktop/Samar/Year_4/Graduation%20Project/Harvard%20Dataset/MobileNetV2.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mDataset5_raw_train.npz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Samar%20Desktop/Samar/Year_4/Graduation%20Project/Harvard%20Dataset/MobileNetV2.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m image_train, image_label_train \u001b[39m=\u001b[39m data_train[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat16)\u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m, data_train[\u001b[39m'\u001b[39m\u001b[39mimage_label\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint8)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m==\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    252\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mopen(key)\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(\u001b[39mbytes\u001b[39;49m,\n\u001b[0;32m    254\u001b[0m                              allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle,\n\u001b[0;32m    255\u001b[0m                              pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    256\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\format.py:763\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m             read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n\u001b[0;32m    762\u001b[0m             read_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(read_count \u001b[39m*\u001b[39m dtype\u001b[39m.\u001b[39mitemsize)\n\u001b[1;32m--> 763\u001b[0m             data \u001b[39m=\u001b[39m _read_bytes(fp, read_size, \u001b[39m\"\u001b[39;49m\u001b[39marray data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    764\u001b[0m             array[i:i\u001b[39m+\u001b[39mread_count] \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfrombuffer(data, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    765\u001b[0m                                                      count\u001b[39m=\u001b[39mread_count)\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\format.py:892\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m     \u001b[39m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    889\u001b[0m     \u001b[39m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    890\u001b[0m     \u001b[39m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 892\u001b[0m         r \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(size \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(data))\n\u001b[0;32m    893\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[0;32m    894\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(r) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m size:\n",
      "File \u001b[1;32mc:\\Users\\abdel\\.conda\\envs\\tensorflow\\lib\\zipfile.py:924\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    923\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[1;32m--> 924\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[0;32m    925\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    926\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\abdel\\.conda\\envs\\tensorflow\\lib\\zipfile.py:1000\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m    999\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1000\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[0;32m   1001\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = np.load('Dataset5_raw_train.npz')\n",
    "image_train, image_label_train = data_train['image'].astype(np.float16)/ 255.0, data_train['image_label'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([image_train[:2326], image_train[2512:4838], image_train[6119:8445], image_train[12234:14560], image_train[16672:18998]])\n",
    "y_train = np.concatenate([image_label_train[:2326], image_label_train[2512:4838], image_label_train[6119:8445], image_label_train[12234:14560], image_label_train[16672:18998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.load('Dataset5_raw_test.npz')\n",
    "image_test, image_label_test = data_test['image'].astype(np.float16)/ 255.0, data_test['image_label'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.concatenate([image_test[:838], image_test[839:1677], image_test[2043:2881], image_test[4083:4921], image_test[5564:6402]])\n",
    "y_test = np.concatenate([image_label_test[:838], image_label_test[839:1677], image_label_test[2043:2881], image_label_test[4083:4921], image_label_test[5564:6402]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = np.load('Dataset5_raw_val.npz')\n",
    "image_val, image_label_val = data_val['image'].astype(np.float16)/ 255.0, data_val['image_label'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.concatenate([image_val[:836], image_val[837:1673], image_val[2040:2876], image_val[4079:4915], image_val[5559:6395]])\n",
    "y_val = np.concatenate([image_label_val[:836], image_label_val[837:1673], image_label_val[2040:2876], image_label_val[4079:4915], image_label_val[5559:6395]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining\n",
    "image_total = np.concatenate([x_train, x_test, x_val])\n",
    "label_total = np.concatenate([y_train, y_test, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into test and train\n",
    "trainX, testX, trainY, testY = train_test_split(image_total, label_total, test_size=0.30, random_state=42)\n",
    "del image_train, image_label_train, image_test, image_label_test, image_val, image_label_val, image_total, label_total, x_train, x_test, x_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mh:\\Samar Desktop\\Samar\\Year_4\\Graduation Project\\Harvard Dataset\\MobileNetV2.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Samar%20Desktop/Samar/Year_4/Graduation%20Project/Harvard%20Dataset/MobileNetV2.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainX\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#set the parameters\n",
    "bs = 16\n",
    "lr = 0.0001\n",
    "shape = (224,224, 3) \n",
    "epochs = 15\n",
    "class_number = 5\n",
    "\n",
    "#define the model by mobilenetv2\n",
    "def MobileNetV2_model(learning_rate, input_shape, class_number):\n",
    "    baseModel = MobileNetV2(include_top=False, input_tensor=Input(shape=input_shape))\n",
    "    for layer in baseModel.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    #baseModel.summary()\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(class_number, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "#compile model\n",
    "model = MobileNetV2_model(lr,shape,class_number)\n",
    "model.compile(loss= \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training ...\n",
      "Epoch 1/15\n",
      "875/875 [==============================] - 68s 73ms/step - loss: 1.2792 - accuracy: 0.5091 - val_loss: 0.5457 - val_accuracy: 0.8205\n",
      "Epoch 2/15\n",
      "875/875 [==============================] - 49s 56ms/step - loss: 0.6542 - accuracy: 0.7786 - val_loss: 0.3991 - val_accuracy: 0.8683\n",
      "Epoch 3/15\n",
      "875/875 [==============================] - 52s 59ms/step - loss: 0.4793 - accuracy: 0.8505 - val_loss: 0.3075 - val_accuracy: 0.8963\n",
      "Epoch 4/15\n",
      "875/875 [==============================] - 48s 55ms/step - loss: 0.3892 - accuracy: 0.8747 - val_loss: 0.2921 - val_accuracy: 0.9053\n",
      "Epoch 5/15\n",
      "875/875 [==============================] - 48s 55ms/step - loss: 0.3281 - accuracy: 0.8971 - val_loss: 0.3173 - val_accuracy: 0.8992\n",
      "Epoch 6/15\n",
      "875/875 [==============================] - 48s 55ms/step - loss: 0.2878 - accuracy: 0.9099 - val_loss: 0.2768 - val_accuracy: 0.9132\n",
      "Epoch 7/15\n",
      "875/875 [==============================] - 50s 57ms/step - loss: 0.2778 - accuracy: 0.9151 - val_loss: 0.2751 - val_accuracy: 0.9162\n",
      "Epoch 8/15\n",
      "875/875 [==============================] - 50s 57ms/step - loss: 0.2246 - accuracy: 0.9269 - val_loss: 0.3373 - val_accuracy: 0.9107\n",
      "Epoch 9/15\n",
      "875/875 [==============================] - 49s 55ms/step - loss: 0.1987 - accuracy: 0.9376 - val_loss: 0.3174 - val_accuracy: 0.9065\n",
      "Epoch 10/15\n",
      "875/875 [==============================] - 49s 57ms/step - loss: 0.1874 - accuracy: 0.9413 - val_loss: 0.3375 - val_accuracy: 0.9107\n",
      "Epoch 11/15\n",
      "875/875 [==============================] - 50s 57ms/step - loss: 0.1609 - accuracy: 0.9521 - val_loss: 0.3449 - val_accuracy: 0.9172\n",
      "Epoch 12/15\n",
      "875/875 [==============================] - 49s 56ms/step - loss: 0.1428 - accuracy: 0.9526 - val_loss: 0.4024 - val_accuracy: 0.9137\n",
      "Epoch 13/15\n",
      "875/875 [==============================] - 48s 55ms/step - loss: 0.1320 - accuracy: 0.9599 - val_loss: 0.3814 - val_accuracy: 0.9175\n",
      "Epoch 14/15\n",
      "875/875 [==============================] - 49s 57ms/step - loss: 0.1183 - accuracy: 0.9634 - val_loss: 0.4074 - val_accuracy: 0.9163\n",
      "Epoch 15/15\n",
      "875/875 [==============================] - 48s 55ms/step - loss: 0.1229 - accuracy: 0.9639 - val_loss: 0.4013 - val_accuracy: 0.9140\n"
     ]
    }
   ],
   "source": [
    "#start the train\n",
    "# TO DO: ADDING EARLY STOPPING\n",
    "print(\"[INFO] training ...\")\n",
    "H = model.fit(trainX, trainY, batch_size=bs, \n",
    "            validation_data=(testX, testY),\t\n",
    "            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "894b3b24c145c270a8b7351330716103ae0f8142438128cd5931ba0aa38e4d56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
